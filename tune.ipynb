{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from GridSearch import GridSearch\n",
    "from keras import backend as K \n",
    "from keras.engine import Layer\n",
    "from keras.layers import Dense, Dropout, Embedding, Flatten, Input, MaxPooling1D\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, MultiTaskElasticNet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "import csv\n",
    "import keras.layers as layers\n",
    "import nltk\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.4.5.\n",
      "The scikit-learn version is 0.22.1.\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "\n",
    "    def __init__(self, models_dict, params_dict):\n",
    "        # if not set(models_dict.keys()).issubset(set(params_dict.keys())):\n",
    "        #     missing_params = list(set(models.keys()) - set(params_dict.keys()))\n",
    "        #     raise ValueError(\n",
    "        #         \"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models_dict\n",
    "        self.params = params_dict\n",
    "        self.keys = models_dict.keys()\n",
    "        #print(self.keys)\n",
    "        self.best_ = {\n",
    "            'estimator': [None],\n",
    "            'params': {},\n",
    "            'y_pred': [],\n",
    "            'r': [],\n",
    "        }\n",
    "\n",
    "    def predict(self):\n",
    "        return self.best_['r']\n",
    "\n",
    "    def tune(self, X_train, y_train, X_test, y_test, **grid_kwargs):\n",
    "        max_r = 0\n",
    "        for key in self.keys:\n",
    "            print(\"\\tRunning GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "\n",
    "            #Pipeline the estimators\n",
    "            pipeline = Pipeline([\n",
    "                ('clf', model),\n",
    "            ])\n",
    "\n",
    "            gs = GridSearchCV(pipeline, params, **grid_kwargs)\n",
    "            gs.fit(X_train, y_train)\n",
    "\n",
    "            print(\"\\tPredicting for %s.\" % key)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            r = np.corrcoef(y_pred, y_test)[0, 1]\n",
    "            print(params)\n",
    "            print(r)\n",
    "\n",
    "            if (abs(r) > abs(max_r)):\n",
    "                self.best_['estimator'] = model\n",
    "                self.best_['params'] = gs.best_params_\n",
    "                self.best_['r'] = r\n",
    "                self.best_['y_pred'] = y_pred\n",
    "\n",
    "            print(\"Current Best\")\n",
    "            #print(self.best_['params'])\n",
    "            print(self.best_['r'])\n",
    "\n",
    "            print('\\tTuning for %s Done.' % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElmoRegressionModel(\n",
    "    dense_dropout_rate=0.5,\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['mse'],\n",
    "    print_summary=False,\n",
    "    include_hidden_layer=False,\n",
    "    hidden_layer_size=64\n",
    "):\n",
    "    inputs, embeddings = [], []\n",
    "    \n",
    "    for idx in range(1, 6):\n",
    "        _input = layers.Input(shape=(1,), dtype=\"string\")\n",
    "        inputs.append(_input)\n",
    "        embedding = ElmoEmbeddingLayer()(_input)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "    concat = layers.concatenate(embeddings)\n",
    "    dense = Dropout(dense_dropout_rate)(concat)\n",
    "    if include_hidden_layer:\n",
    "        dense = layers.Dense(hidden_layer_size, activation='relu')(dense)\n",
    "        dense = Dropout(dense_dropout_rate)(dense)\n",
    "    dense = layers.Dense(1, activation='relu')(dense)# (drop2)\n",
    "    \n",
    "    # If we want to do 5-way prediction within a single network\n",
    "    # dense = layers.Dense(5, activation='relu')(dense)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=dense)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "# Import the process data from R Studio\n",
    "###############################################################################################################\n",
    "data = pd.read_csv(\"mega_dataset.csv\")\n",
    "\n",
    "train_data = data.loc[data.Dataset == \"Train\"]\n",
    "train_data_X = train_data.iloc[:, 13:]\n",
    "train_data_y = train_data.loc[:, train_data.columns.str.contains('_Scale_score')]\n",
    "\n",
    "test_data = data.loc[(data.Dataset == \"Dev\") | (data.Dataset == \"Test\")]\n",
    "test_data_X = test_data.iloc[:, 13:]\n",
    "test_data_y = test_data.loc[:, test_data.columns.str.contains('_Scale_score')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hyperparameter_list = tune(train_data_X, train_data_y, dev_data_X, dev_data_y, selected_feature)\n",
    "best_hyperparameters = []\n",
    "clf_dict = {\n",
    "    'neural': KerasRegressor(build_fn=lambda: ElmoRegressionModel(**model_params)),\n",
    "    'forest': RandomForestRegressor(),\n",
    "    'ridge': Ridge(),\n",
    "    'elastic': ElasticNet(),\n",
    "}\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "param_list = {\n",
    "    'neural': {\n",
    "        'clf__build_fn': [lambda: ElmoRegressionModel(**model_params)],\n",
    "        'clf__epochs': [10],\n",
    "        'clf__batch_size': [32],\n",
    "        'clf__verbose': [1]\n",
    "    },\n",
    "    'forest': {\n",
    "        'clf__n_estimators': [1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 8000, 10000],\n",
    "        'clf__criterion': ['mse'],\n",
    "        'clf__max_depth': max_depth,\n",
    "        'clf__min_samples_split': [2, 3, 4, 5, 6, 10, 12],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "        'clf__min_weight_fraction_leaf': [0.0],\n",
    "        'clf__max_features': ['auto', 'sqrt'],\n",
    "        'clf__max_leaf_nodes': [None],\n",
    "        'clf__min_impurity_decrease': [0.0],\n",
    "        'clf__min_impurity_split': [None],\n",
    "        'clf__bootstrap': [True, False],\n",
    "        'clf__oob_score': [False],\n",
    "        'clf__n_jobs': [None],\n",
    "        'clf__random_state': [None],\n",
    "        'clf__verbose': [0],\n",
    "        'clf__warm_start': [False],\n",
    "        'clf__ccp_alpha': [0.0],\n",
    "        'clf__max_samples': [None]\n",
    "    },\n",
    "    'ridge': {\n",
    "        'clf__alpha': [0.0, 0.05, 0.1, 0.3, 0.5, 0.8, 0.9, 0.95, 1.0, 1.2, 1.8, 10, 100, 10000, 1000000], \n",
    "        'clf__fit_intercept': [True], \n",
    "        'clf__normalize': [False], \n",
    "        'clf__copy_X': [True],\n",
    "        'clf__max_iter': [None],\n",
    "        'clf__tol': [0.001],\n",
    "        'clf__solver': ['auto'],\n",
    "        'clf__random_state': [None],\n",
    "    },\n",
    "    'elastic': {\n",
    "        'clf__alpha': [0.0, 0.05, 0.1, 0.3, 0.5, 0.8, 0.9, 0.95, 1.0, 1.2, 1.8, 10, 100, 10000, 1000000],\n",
    "        'clf__l1_ratio': [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0],\n",
    "        'clf__fit_intercept': [True],\n",
    "        'clf__normalize': [False],\n",
    "        'clf__precompute': [False],\n",
    "        'clf__max_iter': [1000],\n",
    "        'clf__copy_X': [True],\n",
    "        'clf__tol': [0.0001],\n",
    "        'clf__warm_start': [False],\n",
    "        'clf__positive': [False],\n",
    "        'clf__random_state': [None],\n",
    "        'clf__selection': ['cyclic']\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr = {\n",
    "    'neural_r2': None,\n",
    "    'neural_mse': None,\n",
    "    'forest_r2': None,\n",
    "    'forest_mse': None,\n",
    "    'ridge_r2': None,\n",
    "    'ridge_mse': None,\n",
    "    'elastic_r2': None,\n",
    "    'elastic_mse': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Neural Network with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"neural\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"neural\"), cv=10, n_jobs=10, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "neural_y = gs.predict(test_data_X)\n",
    "Corr['neural_r2'] = forest_y.corr(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Neural Network with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"neural\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(key), cv=10, n_jobs=10, verbose=1, scoring='mean_squared_error', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "neural_y = gs.predict(test_data_X)\n",
    "Corr['neural_mse'] = forest_y.corr(test_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Parameter TUning for Random Forest with r2\n",
      "Fitting 10 folds for each of 13104 candidates, totalling 131040 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed: 71.7min\n"
     ]
    }
   ],
   "source": [
    "print('Running Parameter TUning for Random Forest with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"forest\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"forest\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['forest_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Random Forest with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"neural\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(key), cv=10, n_jobs=30, verbose=5, scoring='mean_squared_error', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['forest_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Ridge with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"ridge\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"ridge\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['ridge_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Ridge with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"ridge\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"ridge\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['ridge_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Elastic Net with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"elastic\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"elastic\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['elastic_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Elastic Net with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"elastic\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"elastic\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['elastic_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda84abd5c3f3d54ba8b1c7862e86cff541"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
