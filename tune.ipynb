{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import keras.layers as layers\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import xgboost as xgb\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers import (Dense, Dropout, Embedding, Flatten, Input,\n",
    "                          MaxPooling1D)\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingRegressor,\n",
    "                              RandomForestRegressor)\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfTransformer,\n",
    "                                             TfidfVectorizer)\n",
    "from sklearn.linear_model import (ElasticNet, Lasso, LinearRegression,\n",
    "                                  MultiTaskElasticNet, Ridge)\n",
    "from sklearn.model_selection import (GridSearchCV, LeaveOneOut,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from GridSearch import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The nltk version is 3.4.5.\nThe scikit-learn version is 0.22.1.\nThe tensorflow version is 2.1.0.\n"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "print('The tensorflow version is {}.'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearch:\n",
    "\n",
    "    def __init__(self, models_dict, params_dict):\n",
    "        # if not set(models_dict.keys()).issubset(set(params_dict.keys())):\n",
    "        #     missing_params = list(set(models.keys()) - set(params_dict.keys()))\n",
    "        #     raise ValueError(\n",
    "        #         \"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models_dict\n",
    "        self.params = params_dict\n",
    "        self.keys = models_dict.keys()\n",
    "        #print(self.keys)\n",
    "        self.best_ = {\n",
    "            'estimator': [None],\n",
    "            'params': {},\n",
    "            'y_pred': [],\n",
    "            'r': [],\n",
    "        }\n",
    "\n",
    "    def predict(self):\n",
    "        return self.best_['r']\n",
    "\n",
    "    def tune(self, X_train, y_train, X_test, y_test, **grid_kwargs):\n",
    "        max_r = 0\n",
    "        for key in self.keys:\n",
    "            print(\"\\tRunning GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "\n",
    "            #Pipeline the estimators\n",
    "            pipeline = Pipeline([\n",
    "                ('clf', model),\n",
    "            ])\n",
    "\n",
    "            gs = GridSearchCV(pipeline, params, **grid_kwargs)\n",
    "            gs.fit(X_train, y_train)\n",
    "\n",
    "            print(\"\\tPredicting for %s.\" % key)\n",
    "            y_pred = gs.predict(X_test)\n",
    "            r = np.corrcoef(y_pred, y_test)[0, 1]\n",
    "            print(params)\n",
    "            print(r)\n",
    "\n",
    "            if (abs(r) > abs(max_r)):\n",
    "                self.best_['estimator'] = model\n",
    "                self.best_['params'] = gs.best_params_\n",
    "                self.best_['r'] = r\n",
    "                self.best_['y_pred'] = y_pred\n",
    "\n",
    "            print(\"Current Best\")\n",
    "            #print(self.best_['params'])\n",
    "            print(self.best_['r'])\n",
    "\n",
    "            print('\\tTuning for %s Done.' % key)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elmo Regression Model for Keras Neural Network\n",
    "Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable=True\n",
    "        super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=self.trainable, name=\"{}_module\".format(self.name))\n",
    "        self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "        super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                      as_dict=True,\n",
    "                      signature='default',\n",
    "                      )['default']\n",
    "        return result\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return K.not_equal(inputs, '--PAD--')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.dimensions)\n",
    "\n",
    "def ElmoRegressionModel(\n",
    "    dense_dropout_rate=0.5,\n",
    "    loss='mean_squared_error',\n",
    "    optimizer='adam',\n",
    "    metrics=['mse'],\n",
    "    print_summary=False,\n",
    "    include_hidden_layer=False,\n",
    "    hidden_layer_size=64\n",
    "):\n",
    "    inputs, embeddings = [], []\n",
    "    \n",
    "    for idx in range(1, 6):\n",
    "        _input = layers.Input(shape=(1,), dtype=\"string\")\n",
    "        inputs.append(_input)\n",
    "        embedding = ElmoEmbeddingLayer()(_input)\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "    concat = layers.concatenate(embeddings)\n",
    "    dense = Dropout(dense_dropout_rate)(concat)\n",
    "    if include_hidden_layer:\n",
    "        dense = layers.Dense(hidden_layer_size, activation='relu')(dense)\n",
    "        dense = Dropout(dense_dropout_rate)(dense)\n",
    "    dense = layers.Dense(1, activation='relu')(dense)# (drop2)\n",
    "    \n",
    "    # If we want to do 5-way prediction within a single network\n",
    "    # dense = layers.Dense(5, activation='relu')(dense)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=dense)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    \n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "# Import the process data from R Studio\n",
    "###############################################################################################################\n",
    "data = pd.read_csv(\"mega_dataset.csv\")\n",
    "\n",
    "train_data = data.loc[data.Dataset == \"Train\"]\n",
    "train_data_X = train_data.iloc[:, 13:]\n",
    "train_data_y = train_data.loc[:, train_data.columns.str.contains('_Scale_score')]\n",
    "\n",
    "test_data = data.loc[(data.Dataset == \"Dev\") | (data.Dataset == \"Test\")]\n",
    "test_data_X = test_data.iloc[:, 13:]\n",
    "test_data_y = test_data.loc[:, test_data.columns.str.contains('_Scale_score')]\n",
    "ATTRIBUTE_LIST = [\"E_Scale_score\", \"A_Scale_score\", \"O_Scale_score\", \"C_Scale_score\", \"N_Scale_score\"]\n",
    "#Y = np.array(train_raw_df[[att + \"_Scale_score\" for att in ATTRIBUTE_LIST]].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0       2.250000\n1       4.666667\n2       2.250000\n3       2.916667\n4       3.750000\n          ...   \n1083    2.500000\n1084    3.000000\n1085    3.833333\n1086    4.500000\n1087    2.750000\nName: E_Scale_score, Length: 1088, dtype: float64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_y[\"E_Scale_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_hyperparameter_list = tune(train_data_X, train_data_y, dev_data_X, dev_data_y, selected_feature)\n",
    "best_hyperparameters = []\n",
    "clf_dict = {\n",
    "    'neural': KerasRegressor(build_fn=lambda: ElmoRegressionModel(**model_params)),\n",
    "    'forest': RandomForestRegressor(),\n",
    "    'ridge': Ridge(),\n",
    "    'elastic': ElasticNet(),\n",
    "}\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "param_list = {\n",
    "    'neural': {\n",
    "        # 'clf__build_fn': [lambda: ElmoRegressionModel(**model_params)],\n",
    "        'clf__epochs': [10,20],\n",
    "        'clf__batch_size': [10, 20, 32, 40, 60, 80, 100, 128],\n",
    "        # 'clf__optimizer' : ['Adam', 'Nadam'],\n",
    "        # 'clf__dropout_rate' : [0.2, 0.3],\n",
    "        # 'clf__activation' : ['relu', 'elu']\n",
    "    },\n",
    "    'forest': {\n",
    "        'clf__n_estimators': [1000, 1500, 2000, 2500, 3000, 3500, 4000, 5000, 8000, 10000],\n",
    "        'clf__criterion': ['mse'],\n",
    "        'clf__max_depth': max_depth,\n",
    "        'clf__min_samples_split': [2, 3, 4, 5, 6, 10, 12],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "        'clf__min_weight_fraction_leaf': [0.0],\n",
    "        'clf__max_features': ['auto', 'sqrt'],\n",
    "        'clf__max_leaf_nodes': [None],\n",
    "        'clf__min_impurity_decrease': [0.0],\n",
    "        'clf__min_impurity_split': [None],\n",
    "        'clf__bootstrap': [True, False],\n",
    "        'clf__oob_score': [False],\n",
    "        'clf__n_jobs': [None],\n",
    "        'clf__random_state': [None],\n",
    "        'clf__verbose': [0],\n",
    "        'clf__warm_start': [False],\n",
    "        'clf__ccp_alpha': [0.0],\n",
    "        'clf__max_samples': [None]\n",
    "    },\n",
    "    'ridge': {\n",
    "        'clf__alpha': [0.0, 0.05, 0.1, 0.3, 0.5, 0.8, 0.9, 0.95, 1.0, 1.2, 1.8, 10, 100, 10000, 1000000], \n",
    "        'clf__fit_intercept': [True], \n",
    "        'clf__normalize': [False], \n",
    "        'clf__copy_X': [True],\n",
    "        'clf__max_iter': [None],\n",
    "        'clf__tol': [0.001],\n",
    "        'clf__solver': ['auto'],\n",
    "        'clf__random_state': [None],\n",
    "    },\n",
    "    'elastic': {\n",
    "        'clf__alpha': [0.0, 0.05, 0.1, 0.3, 0.5, 0.8, 0.9, 0.95, 1.0, 1.2, 1.8, 10, 100, 10000, 1000000],\n",
    "        'clf__l1_ratio': [0.0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0],\n",
    "        'clf__fit_intercept': [True],\n",
    "        'clf__normalize': [False],\n",
    "        'clf__precompute': [False],\n",
    "        'clf__max_iter': [1000],\n",
    "        'clf__copy_X': [True],\n",
    "        'clf__tol': [0.0001],\n",
    "        'clf__warm_start': [False],\n",
    "        'clf__positive': [False],\n",
    "        'clf__random_state': [None],\n",
    "        'clf__selection': ['cyclic']\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corr = {\n",
    "    'neural_r2': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'neural_mse': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'forest_r2': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'forest_mse': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'ridge_r2': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'ridge_mse': {\"O_Scale_score\": None,\n",
    "                \"C_Scale_score\": None,\n",
    "                \"E_Scale_score\": None,\n",
    "                \"A_Scale_score\": None,\n",
    "                \"N_Scale_score\": None},\n",
    "    'elastic_r2': None,\n",
    "    'elastic_mse': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Running Parameter TUning for Neural Network with r2\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-6b956dc0e464>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running Parameter TUning for Neural Network with r2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Initialize session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "print('Running Parameter TUning for Neural Network with r2')\n",
    "# Initialize session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.WARNING)\n",
    "# Make sure we have a GPU - else this'll take a lifetime or two\n",
    "sess.list_devices()\n",
    "ATTRIBUTE_MODEL_PARAMS = [\n",
    "    dict(dense_dropout_rate=0.7),\n",
    "    dict(dense_dropout_rate=0.7),\n",
    "    dict(dense_dropout_rate=0.7),\n",
    "    dict(dense_dropout_rate=0.7),\n",
    "    dict(include_hidden_layer=True, dense_dropout_rate=0.2),\n",
    "]\n",
    "\n",
    "for idx, att in enumerate(ATTRIBUTE_LIST):\n",
    "    print(\"Training for attribute {}\".format(att))\n",
    "    model_params = ATTRIBUTE_MODEL_PARAMS[idx]\n",
    "\n",
    "    clf = KerasRegressor(\n",
    "        build_fn=lambda: ElmoRegressionModel(**model_params),\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    pipe = Pipeline([('clf', clf)])\n",
    "    gs = GridSearchCV(pipe, param_list.get(\"neural\"), cv=10, n_jobs=10, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "    gs.fit(train_data_X, train_data_y[att])\n",
    "\n",
    "    neural_y = gs.predict(test_data_X)\n",
    "    Corr['neural_r2'][att] = neural_y.corr(test_data_y[att])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Neural Network with mse')\n",
    "\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"neural\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(key), cv=10, n_jobs=10, verbose=1, scoring='mean_squared_error', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "neural_y = gs.predict(test_data_X)\n",
    "Corr['neural_mse'] = forest_y.corr(test_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Random Forest with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"forest\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"forest\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['forest_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Random Forest with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"neural\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(key), cv=10, n_jobs=30, verbose=5, scoring='mean_squared_error', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['forest_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Ridge with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"ridge\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"ridge\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['ridge_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Ridge with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"ridge\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"ridge\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['ridge_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Elastic Net with r2')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"elastic\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"elastic\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['elastic_r2'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running Parameter TUning for Elastic Net with mse')\n",
    "pipe = Pipeline([('clf', clf_dict.get(\"elastic\"))])\n",
    "gs = GridSearchCV(pipe, param_list.get(\"elastic\"), cv=10, n_jobs=30, verbose=5, scoring='r2', return_train_score=False, error_score='raise', iid=True)\n",
    "gs.fit(train_data_X, train_data_y)\n",
    "forest_y = gs.predict(test_data_X)\n",
    "Corr['elastic_mse'] = forest_y.corr(test_data_y)\n",
    "Corr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}